强化学习是一种经典的机器学习方法，它关注智能体和环境之间的交互，目标一般为追求最大回报。换而言之，强化学习是一种学习如何从状态映射到行为以使得获取的奖励最大的学习机制。这样的一个主体需要不断地在环境中进行实验，通过环境给予的反馈（奖励）来不断优化“状态-行为”的对应关系。因此，反复实验（rial and error）和延迟奖励（delayed reward）是强化学习最重要的两个特征。

对于迷宫游戏，我们可以通过对迷宫的每个点位设置不同的回报值，而在强化游戏中，AI会自发追求最大回报，因此可以实现自发寻找终点，避开陷阱的效果。

强化学习系统一般包括四个要素：策略（policy），奖励（reward），价值（value），环境（environment）。而在本软件中其四要素对应的对象为：

l 策略（policy）：Q-learning算法

l 奖励（reward）：为终点赋予较高回报值

l 价值（value）：对于迷宫点位赋予的回报值

l 环境（environment）：生成的迷宫环境

其中，Q-learning算法是一种基于价值的算法。在算法中，Q函数有两个参数（state, action），分别代表状态和决策，其值代表AI在当前状态下采取决策获得的价值。而算法的目标即为最大化价值来获取较高的回报值。而Q-learning算法采用Q table记录不同状态和不同决策下的价值，在初始化Q table后，训练主体在环境中不断探索，并使用贝尔曼方程（ballman equation）来迭代，随着迭代不断拟合Q函数，最终达到收敛或迭代结束。此方法在迷宫问题中效率极佳，故本系统采用Q-learning算法来训练AI。

针对问题分析，我们首先通过查阅资料的方式，确定采用强化学习中的Q-learning算法作为系统的核心算法。而对于训练后结果，可视化过程也非常重要， 对训练结果进行可视化操作，可以使用户更方便快捷的理解训练过程和训练结果，所以我们认为系统有必要进行可视化操作。最后，近些年来python语言在机器学习和可视化方面的优异表现，我们选用python作为系统的主要语言。

对于课设的实现过程，我们首先将问题进行模块化分析，由于python是强对象语言，于是我们将实现过程转化为几个关键类的构造，对于迷宫游戏，将其拆解为迷宫（Maze），机器人（Robot），程序框架（Runner），面板（UI）四个模块，分别进行编写。最后程序的实现由四个对象之间的交互完成。